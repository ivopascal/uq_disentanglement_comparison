{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4e911b5-0055-4bb1-884d-2a2e1ee123eb",
   "metadata": {},
   "source": [
    "from sklearn.datasets import make_blobs, make_moons\n",
    "import numpy as np\n",
    "from keras.models import Sequential, Model\n",
    "from keras_uncertainty.layers import StochasticDropout, SamplingSoftmax\n",
    "from keras_uncertainty.models import DisentangledStochasticClassifier, StochasticClassifier\n",
    "from keras.layers import Dense, Input, Dropout\n",
    "from keras_uncertainty.utils import numpy_entropy\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def uncertainty(probs):\n",
    "    return numpy_entropy(probs, axis=-1)\n",
    "\n",
    "\n",
    "X, y = make_moons(n_samples=1000, noise=0.1, random_state=0)\n",
    "BATCH_SIZE = 256\n",
    "NUM_SAMPLES = 50"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1238421-3ac7-4ee4-87b6-bc77b77e8801",
   "metadata": {},
   "source": [
    "from disentanglement.models.information_theoretic_models import train_it_model, expected_entropy, mutual_information\n",
    "from disentanglement.models.gaussian_logits_models import train_gaussian_logits_model\n",
    "from disentanglement.models.architectures import get_blobs_dropout_architecture\n",
    "\n",
    "it_ensemble_model = train_it_model(get_blobs_dropout_architecture, X, y, n_classes=2, epochs=100)\n",
    "gl_ensemble_model = train_gaussian_logits_model(get_blobs_dropout_architecture, X, y, n_classes=2, epochs=100)\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8f5ae8d-be01-4552-9cac-69af4c2e285f",
   "metadata": {},
   "source": [
    "min_x, max_x = [-3, -3] , [3, 3]\n",
    "res = 0.1\n",
    "\n",
    "xx, yy = np.meshgrid(np.arange(min_x[0], max_x[0], res), np.arange(min_x[1], max_x[1], res))\n",
    "domain = np.c_[xx.ravel(), yy.ravel()]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec397466-f943-4605-802e-27a9d0cce4e3",
   "metadata": {},
   "source": [
    "it_preds = it_ensemble_model.predict_samples(domain, num_samples=50, batch_size=128)\n",
    "\n",
    "it_ale = expected_entropy(it_preds).reshape(xx.shape)\n",
    "it_epi = mutual_information(it_preds).reshape(xx.shape)\n",
    "\n",
    "\n",
    "pred_mean, pred_ale_std, pred_epi_std = gl_ensemble_model.predict(domain, batch_size=128, num_samples=50)\n",
    "\n",
    "gl_ale = uncertainty(pred_ale_std).reshape(xx.shape)\n",
    "gl_epi = uncertainty(pred_epi_std).reshape(xx.shape)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6c99bc-57c5-486d-a684-5dc06cb3080f",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "526ff1b8-1524-4832-9eb5-0f76aa310c25",
   "metadata": {},
   "source": [
    "import matplotlib.pylab as pl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "sns.reset_orig()\n",
    "\n",
    "cmap = pl.cm.binary\n",
    "my_cmap = cmap(np.arange(cmap.N))\n",
    "#my_cmap[:, 0] = 0.0\n",
    "my_cmap[:, -1] = 0.7\n",
    "my_cmap = ListedColormap(my_cmap)\n",
    "\n",
    "\n",
    "fig, axes =  plt.subplots(ncols=1, nrows=4, figsize=(6, 10), squeeze=False)    \n",
    "ax_ale_it = axes[0][0]\n",
    "ax_epi_it = axes[1][0]\n",
    "ax_ale_gl = axes[2][0]\n",
    "ax_epi_gl = axes[3][0]\n",
    "\n",
    "cf_ale = ax_ale_it.contourf(xx, yy, it_ale, antialiased=True)\n",
    "ax_ale_it.scatter(X[:, 0], X[:, 1], c=y, cmap=my_cmap)\n",
    "ax_ale_it.get_xaxis().set_ticks([])\n",
    "ax_ale_it.get_yaxis().set_ticks([])\n",
    "ax_ale_it.autoscale(False)\n",
    "\n",
    "cf_epi = ax_epi_it.contourf(xx, yy, it_epi, antialiased=True)\n",
    "ax_epi_it.scatter(X[:, 0], X[:, 1], c=y, cmap=my_cmap)\n",
    "ax_epi_it.get_xaxis().set_ticks([])\n",
    "ax_epi_it.get_yaxis().set_ticks([])\n",
    "ax_epi_it.autoscale(False)\n",
    "\n",
    "ax_ale_it.set_ylabel(\"Aleatoric (IT)\")\n",
    "ax_epi_it.set_ylabel(\"Epistemic (IT)\") \n",
    "\n",
    "\n",
    "\n",
    "cf_ale = ax_ale_gl.contourf(xx, yy, gl_ale, antialiased=True)\n",
    "ax_ale_gl.scatter(X[:, 0], X[:, 1], c=y, cmap=my_cmap)\n",
    "ax_ale_gl.get_xaxis().set_ticks([])\n",
    "ax_ale_gl.get_yaxis().set_ticks([])\n",
    "ax_ale_gl.autoscale(False)\n",
    "\n",
    "cf_epi = ax_epi_gl.contourf(xx, yy, gl_epi, antialiased=True)\n",
    "ax_epi_gl.scatter(X[:, 0], X[:, 1], c=y, cmap=my_cmap)\n",
    "ax_epi_gl.get_xaxis().set_ticks([])\n",
    "ax_epi_gl.get_yaxis().set_ticks([])\n",
    "ax_epi_gl.autoscale(False)\n",
    "\n",
    "ax_ale_gl.set_ylabel(\"Aleatoric (GL)\")\n",
    "ax_epi_gl.set_ylabel(\"Epistemic (GL)\") \n",
    "\n",
    "\n",
    "\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d4450971-c1dd-4f90-a20d-4cbad57915da",
   "metadata": {},
   "source": [
    "from sklearn.utils import shuffle\n",
    "import seaborn as sns\n",
    "\n",
    "fontsize = 80\n",
    "sns.reset_orig()\n",
    "# plt.rcParams.update({'font.size':fontsize})\n",
    "\n",
    "\n",
    "noise_rates = [0.01, 0.05, 0.1, 0.25, 0.5, 0.75, 1.0]\n",
    "epochs = 100\n",
    "figure_width = 48.48\n",
    "figure_ratio = 0.5\n",
    "\n",
    "fig, axes =  plt.subplots(ncols=len(noise_rates), nrows=4, figsize=(figure_width, figure_width * figure_ratio), squeeze=True)    \n",
    "\n",
    "\n",
    "res = 0.1\n",
    "min_x, max_x = [-3, -3] , [3 + res, 3 + res]\n",
    "\n",
    "xx, yy = np.meshgrid(np.arange(min_x[0], max_x[0], res), np.arange(min_x[1], max_x[1], res))\n",
    "domain = np.c_[xx.ravel(), yy.ravel()]\n",
    "\n",
    "\n",
    "def partial_shuffle_dataset(x, y, percentage):\n",
    "    x_noisy, y_noisy = shuffle(x, y)\n",
    "    np.random.shuffle(y_noisy[:int(len(y_noisy) * percentage)])\n",
    "    x_noisy, y_noisy = shuffle(x_noisy, y_noisy)\n",
    "    return x_noisy, y_noisy\n",
    "\n",
    "\n",
    "for idx, noise_rate in enumerate(noise_rates):\n",
    "    X, y = make_moons(n_samples=1000, noise=0.1)\n",
    "    X, y = partial_shuffle_dataset(X, y, noise_rate)\n",
    "    it_ensemble_model = train_it_model(get_blobs_dropout_architecture, X, y, n_classes=2, epochs=epochs)\n",
    "    gl_ensemble_model = train_gaussian_logits_model(get_blobs_dropout_architecture, X, y, n_classes=2, epochs=epochs)\n",
    "\n",
    "\n",
    "    it_preds = it_ensemble_model.predict_samples(domain, num_samples=50, batch_size=128)\n",
    "\n",
    "    it_ale = expected_entropy(it_preds).reshape(xx.shape)\n",
    "    it_epi = mutual_information(it_preds).reshape(xx.shape)\n",
    "    \n",
    "    \n",
    "    pred_mean, pred_ale_std, pred_epi_std = gl_ensemble_model.predict(domain, batch_size=128, num_samples=50)\n",
    "    \n",
    "    gl_ale = uncertainty(pred_ale_std).reshape(xx.shape)\n",
    "    gl_epi = uncertainty(pred_epi_std).reshape(xx.shape)\n",
    "\n",
    "\n",
    "    ax_ale_it = axes[0][idx]\n",
    "    ax_epi_it = axes[1][idx]\n",
    "    ax_ale_gl = axes[2][idx]\n",
    "    ax_epi_gl = axes[3][idx]\n",
    "    \n",
    "    cf_ale = ax_ale_it.contourf(xx, yy, it_ale, antialiased=False, vmin=0.0, vmax=np.log(2.0))\n",
    "    ax_ale_it.get_xaxis().set_ticks([])\n",
    "    ax_ale_it.get_yaxis().set_ticks([])\n",
    "    ax_ale_it.autoscale(False)\n",
    "    \n",
    "    cf_epi = ax_epi_it.contourf(xx, yy, it_epi, antialiased=False, vmin=0.0, vmax=np.log(2.0))\n",
    "    ax_epi_it.get_xaxis().set_ticks([])\n",
    "    ax_epi_it.get_yaxis().set_ticks([])\n",
    "    ax_epi_it.autoscale(False)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    cf_ale = ax_ale_gl.contourf(xx, yy, gl_ale, antialiased=False, vmin=0.0, vmax=np.log(2.0))\n",
    "    ax_ale_gl.get_xaxis().set_ticks([])\n",
    "    ax_ale_gl.get_yaxis().set_ticks([])\n",
    "    ax_ale_gl.autoscale(False)\n",
    "    \n",
    "    cf_epi = ax_epi_gl.contourf(xx, yy, gl_epi, antialiased=False, vmin=0.0, vmax=np.log(2.0))\n",
    "    ax_epi_gl.get_xaxis().set_ticks([])\n",
    "    ax_epi_gl.get_yaxis().set_ticks([])\n",
    "    ax_epi_gl.autoscale(False)\n",
    "    ax_ale_it.set_title(f\"{int(noise_rate * 100)}%\", fontsize=fontsize)\n",
    "\n",
    "    if idx == 0:\n",
    "        ax_ale_it.set_ylabel(\"Ale (IT)\", fontsize=fontsize)\n",
    "        ax_epi_it.set_ylabel(\"Epi (IT)\", fontsize=fontsize) \n",
    "        \n",
    "        ax_ale_gl.set_ylabel(\"Ale (GL)\", fontsize=fontsize)\n",
    "        ax_epi_gl.set_ylabel(\"Epi (GL)\", fontsize=fontsize)\n",
    "\n",
    "    if idx == 0 or idx == len(noise_rates)-1:\n",
    "        ax_epi_gl.scatter(X[:, 0], X[:, 1], c=y, cmap=my_cmap)\n",
    "        ax_ale_gl.scatter(X[:, 0], X[:, 1], c=y, cmap=my_cmap)\n",
    "        ax_epi_it.scatter(X[:, 0], X[:, 1], c=y, cmap=my_cmap)\n",
    "        ax_ale_it.scatter(X[:, 0], X[:, 1], c=y, cmap=my_cmap)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\"label_noise_two_moons.pdf\")\n",
    "plt.show()\n",
    "    \n",
    "        "
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39f26073-c9eb-4a07-b761-b37459171961",
   "metadata": {},
   "source": [
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4433c03-268a-4705-9941-fbbade2d807b",
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
